library("rvest")
db <- dbConnect(RSQLite::SQLite(), dbname="news_saturation (research).sqlite")
news <- dbGetQuery(db, "SELECT * FROM top_news")
sources <- c("associated-press","al-jazeera-english","bbc-news","bloomberg",
"business-insider","breitbart-news","cnbc","cnn","google-news",
"independent","reuters","the-economist", "the-huffington-post",
"newsweek","the-new-york-times","the-wall-street-journal",
"the-washington-post","time","usa-today")
ap <- news$articles.url[news$source==sources[1]][1]
page <- xml2::read_html(ap)
content <- rvest::html_nodes(page, ".p")
text <- rvest::html_text(content) #convert to words
substr(text, 1, 2000)
text
library(RSQLite)
library(tidyverse)
library(tm)
library("XML")
library("rvest")
db <- dbConnect(RSQLite::SQLite(), dbname="news_saturation (research).sqlite")
news <- dbGetQuery(db, "SELECT * FROM top_news")
sources <- c("associated-press","al-jazeera-english","bbc-news","bloomberg",
"business-insider","breitbart-news","cnbc","cnn","google-news",
"independent","reuters","the-economist", "the-huffington-post",
"newsweek","the-new-york-times","the-wall-street-journal",
"the-washington-post","time","usa-today")
ap <- news$articles.url[news$source==sources[1]][1]
page <- xml2::read_html(ap)
content <- rvest::html_nodes(page, "p")
text <- rvest::html_text(content) #convert to words
substr(text, 1, 2000)
dim(text)
library(RSQLite)
library(tidyverse)
library(tm)
library("XML")
library("rvest")
db <- dbConnect(RSQLite::SQLite(), dbname="news_saturation (research).sqlite")
news <- dbGetQuery(db, "SELECT * FROM top_news")
sources <- c("associated-press","al-jazeera-english","bbc-news","bloomberg",
"business-insider","breitbart-news","cnbc","cnn","google-news",
"independent","reuters","the-economist", "the-huffington-post",
"newsweek","the-new-york-times","the-wall-street-journal",
"the-washington-post","time","usa-today")
ap <- news$articles.url[news$source==sources[1]][1]
page <- xml2::read_html(ap)
content <- rvest::html_nodes(page, "p")
text <- rvest::html_text(content) #convert to words
class(text)
text
ap
head(text)
head(text, 20)
a <- head(text)
a
?substr
substr(a, 0,2)
substr(a, 0,1)
grepl(substr(a, 0,1), a)
map_lgl(a, function(x) grepl(xsubstr(0,1), x))
a
map_lgl(a, function(x) grepl(substr(0,1), x))
map_lgl(a, function(x) grepl(substr(x, 0,1), x))
text %>%
map_lgl(function(x) grepl(substr(x, 0,1), x))
length(text)
text
substring(a, 0, 1)
substr(a, 0, 1)
substr(text, 0, 1)
substr(text, 0, 1) == "\n"
text[substr(text, 0, 1) == "\n"]
text[substr(text, 0, 1) != "\n"]
library(RSQLite)
library(tidyverse)
library(tm)
library("XML")
library("rvest")
db <- dbConnect(RSQLite::SQLite(), dbname="news_saturation (research).sqlite")
news <- dbGetQuery(db, "SELECT * FROM top_news")
sources <- c("associated-press","al-jazeera-english","bbc-news","bloomberg",
"business-insider","breitbart-news","cnbc","cnn","google-news",
"independent","reuters","the-economist", "the-huffington-post",
"newsweek","the-new-york-times","the-wall-street-journal",
"the-washington-post","time","usa-today")
ap <- news$articles.url[news$source==sources[1]][1]
page <- xml2::read_html(ap)
content <- rvest::html_nodes(page, "p")
text <- rvest::html_text(content)
#convert to words
# remove photo and link captions
text[substr(text, 0, 1) != "\n"]
library(RSQLite)
library(tidyverse)
library(tm)
library("XML")
library("rvest")
db <- dbConnect(RSQLite::SQLite(), dbname="news_saturation (research).sqlite")
news <- dbGetQuery(db, "SELECT * FROM top_news")
sources <- c("associated-press","al-jazeera-english","bbc-news","bloomberg",
"business-insider","breitbart-news","cnbc","cnn","google-news",
"independent","reuters","the-economist", "the-huffington-post",
"newsweek","the-new-york-times","the-wall-street-journal",
"the-washington-post","time","usa-today")
ap <- news$articles.url[news$source==sources[1]][1]
page <- xml2::read_html(ap)
content <- rvest::html_nodes(page, "p")
text <- rvest::html_text(content)
#convert to words
# remove photo and link captions
a <- text[substr(text, 0, 1) != "\n"]
length(a)
duplicated(a)
a[grepl("---",a)]
a
a[grepl("___",a)]
a[grep("___",a)]
grep("___",a)
cutoff <- grep("___",a)[1]
a[1:cutoff-1]
library(RSQLite)
library(tidyverse)
library(tm)
library("XML")
library("rvest")
db <- dbConnect(RSQLite::SQLite(), dbname="news_saturation (research).sqlite")
news <- dbGetQuery(db, "SELECT * FROM top_news")
sources <- c("associated-press","al-jazeera-english","bbc-news","bloomberg",
"business-insider","breitbart-news","cnbc","cnn","google-news",
"independent","reuters","the-economist", "the-huffington-post",
"newsweek","the-new-york-times","the-wall-street-journal",
"the-washington-post","time","usa-today")
ap <- news$articles.url[news$source==sources[1]][1]
page <- xml2::read_html(ap)
content <- rvest::html_nodes(page, "p")
text <- rvest::html_text(content)
#convert to words
# remove photo and link captions
text <- text[substr(text, 0, 1) != "\n"]
cutoff <- grep("___",  text)[1]
text <- a[1:cutoff-1]
text
w <- 2
ap <- news$articles.url[news$source==sources[1]][w]
page <- xml2::read_html(ap)
content <- rvest::html_nodes(page, "p")
text <- rvest::html_text(content)
#convert to words
# remove photo and link captions
text <- text[substr(text, 0, 1) != "\n"]
cutoff <- grep("___",  text)[1]
text <- a[1:cutoff-1]
text
ap
w <- 2
ap <- news$articles.url[news$source==sources[1]][w]
page <- xml2::read_html(ap)
content <- rvest::html_nodes(page, "p")
text <- rvest::html_text(content)
#convert to words
text
w <- 2
ap <- news$articles.url[news$source==sources[1]][w]
page <- xml2::read_html(ap)
content <- rvest::html_nodes(page, "p")
text <- rvest::html_text(content)
#convert to words
# remove photo and link captions
text <- text[substr(text, 0, 1) != "\n"]
cutoff <- grep("___",  text)[1] - 1
text <- text[1:cutoff]
text
w <- 3
w <- 3
ap <- news$articles.url[news$source==sources[1]][w]
page <- xml2::read_html(ap)
content <- rvest::html_nodes(page, "p")
text <- rvest::html_text(content)
#convert to words
# remove photo and link captions
text <- text[substr(text, 0, 1) != "\n"]
cutoff <- grep("___",  text)[1] - 1
text <- text[1:cutoff]
text
ap
cutoff
1:5[1:NA]
cutoff
text[1:cutoff]
library(RSQLite)
library(tidyverse)
library(tm)
library("XML")
library("rvest")
db <- dbConnect(RSQLite::SQLite(), dbname="news_saturation (research).sqlite")
news <- dbGetQuery(db, "SELECT * FROM top_news")
sources <- c("associated-press","al-jazeera-english","bbc-news","bloomberg",
"business-insider","breitbart-news","cnbc","cnn","google-news",
"independent","reuters","the-economist", "the-huffington-post",
"newsweek","the-new-york-times","the-wall-street-journal",
"the-washington-post","time","usa-today")
# ----------------
# Associated Press
# ----------------
w <- 3
ap <- news$articles.url[news$source==sources[1]][w]
page <- xml2::read_html(ap)
content <- rvest::html_nodes(page, "p")
text <- rvest::html_text(content)
#convert to words
# remove photo and link captions
text <- text[substr(text, 0, 1) != "\n"]
cutoff <- grep("___",  text)[1] - 1
if(!is.na(cutoff){
text <- text[1:cutoff]}
text
text[c(1, length(text))]
# Associated Press
# ----------------
w <- 4
ap <- news$articles.url[news$source==sources[1]][w]
page <- xml2::read_html(ap)
content <- rvest::html_nodes(page, "p")
text <- rvest::html_text(content)
#convert to words
# remove photo and link captions
text <- text[substr(text, 0, 1) != "\n"]
cutoff <- grep("___",  text)[1] - 1
if(!is.na(cutoff){
text <- text[1:cutoff]}
# check
text[c(1, length(text))]
ap
cutoff
library(RSQLite)
library(tidyverse)
library(tm)
library("XML")
library("rvest")
db <- dbConnect(RSQLite::SQLite(), dbname="news_saturation (research).sqlite")
news <- dbGetQuery(db, "SELECT * FROM top_news")
sources <- c("associated-press","al-jazeera-english","bbc-news","bloomberg",
"business-insider","breitbart-news","cnbc","cnn","google-news",
"independent","reuters","the-economist", "the-huffington-post",
"newsweek","the-new-york-times","the-wall-street-journal",
"the-washington-post","time","usa-today")
# ----------------
# Associated Press
# ----------------
w <- 4
ap <- news$articles.url[news$source==sources[1]][w]
page <- xml2::read_html(ap)
content <- rvest::html_nodes(page, "p")
text <- rvest::html_text(content)
#convert to words
# remove photo and link captions
text <- text[substr(text, 0, 1) != "\n"]
cutoff <- grep("___",  text)[1] - 1
text
cutoff
library(RSQLite)
library(tidyverse)
library(tm)
library("XML")
library("rvest")
db <- dbConnect(RSQLite::SQLite(), dbname="news_saturation (research).sqlite")
news <- dbGetQuery(db, "SELECT * FROM top_news")
sources <- c("associated-press","al-jazeera-english","bbc-news","bloomberg",
"business-insider","breitbart-news","cnbc","cnn","google-news",
"independent","reuters","the-economist", "the-huffington-post",
"newsweek","the-new-york-times","the-wall-street-journal",
"the-washington-post","time","usa-today")
# ----------------
# Associated Press
# ----------------
w <- 4
ap <- news$articles.url[news$source==sources[1]][w]
page <- xml2::read_html(ap)
content <- rvest::html_nodes(page, "p")
text <- rvest::html_text(content)
#convert to words
# remove photo and link captions at beginning if there
text <- text[substr(text, 0, 1) != "\n"]
text
cutoff <- grep("___",  text)[1] - 1
cutoff
text <- text[1:cutoff]}
w <- 4
ap <- news$articles.url[news$source==sources[1]][w]
page <- xml2::read_html(ap)
content <- rvest::html_nodes(page, "p")
text <- rvest::html_text(content)
#convert to words
# remove photo and link captions at beginning if there
text <- text[substr(text, 0, 1) != "\n"]
cutoff <- grep("___",  text)[1] - 1
if(!is.na(cutoff)){
text <- text[1:cutoff]}
# check
text[c(1, length(text))]
ap
w <- 5
ap <- news$articles.url[news$source==sources[1]][w]
page <- xml2::read_html(ap)
text <- rvest::html_text(content)
content <- rvest::html_nodes(page, "p")
text <- text[substr(text, 0, 1) != "\n"]
if(!is.na(cutoff)){
text <- text[1:cutoff]}
cutoff <- grep("___",  text)[1] - 1
text[c(1, length(text))]
ap
# ----------------
w <- 5
ap <- news$articles.url[news$source==sources[1]][w]
page <- xml2::read_html(ap)
content <- rvest::html_nodes(page, "p")
text <- rvest::html_text(content)
#convert to words
# remove photo and link captions at beginning if there
text <- text[substr(text, 0, 1) != "\n"]
cutoff <- grep("___",  text)[1] - 1
if(!is.na(cutoff)){
text <- text[1:cutoff]}
# check
text[c(1, length(text))]
ap
# ----------------
w <- 16
ap <- news$articles.url[news$source==sources[1]][w]
page <- xml2::read_html(ap)
content <- rvest::html_nodes(page, "p")
text <- rvest::html_text(content)
#convert to words
# remove photo and link captions from beginning
text <- text[substr(text, 0, 1) != "\n"]
cutoff <- grep("___",  text)[1] - 1
# remove authors/credits from end
if(!is.na(cutoff)){
text <- text[1:cutoff]}
# check
text[c(1, length(text))]
ap
w <- 30
ap <- news$articles.url[news$source==sources[1]][w]
page <- xml2::read_html(ap)
content <- rvest::html_nodes(page, "p")
text <- rvest::html_text(content)
#convert to words
# remove photo and link captions from beginning
text <- text[substr(text, 0, 1) != "\n"]
cutoff <- grep("___",  text)[1] - 1
# remove authors/credits from end
if(!is.na(cutoff)){
text <- text[1:cutoff]}
# check
text[c(1, length(text))]
ap
text
paste(text, collapse = "|")
paste(text, collapse = " | ")
paste0(text, collapse = " | ")
text <- paste0(text, collapse = " | ")
text
text
iconv(text, from="UTF-8", to="ASCII")
icon(text, from="UTF-8", to="ASCII")
iconv(text, to="ASCII")
gsub("*.(AP)", "", text)
gsub(".(AP)", "", text)
gsub("*(AP)", "", text)
gsub(".(AP)", "", text)
gsub(".*(AP)", "", text)
gsub(".*(AP))", "", text)
gsub(".*(AP)) ", "", text)
scrape_news <- function(news_source, news_url){
page <- xml2::read_html(news_url)
if(news_source=="associated-press"){
# get particular content from page
content <- rvest::html_nodes(page, "p")
#convert to words
text <- rvest::html_text(content)
# remove photo and link captions from beginning
text <- text[substr(text, 0, 1) != "\n"]
# remove authors/credits from end
cutoff <- grep("___",  text)[1] - 1
if(!is.na(cutoff)){
text <- text[1:cutoff]}
# collapse vector into one string
text <- paste0(text, collapse = " | ")
# remove city from beginning of article
text <- gsub(".*(AP)) ", "", text)}
text
}
library(RSQLite)
library(tidyverse)
library(tm)
library("XML")
library("rvest")
db <- dbConnect(RSQLite::SQLite(), dbname="news_saturation (research).sqlite")
news <- dbGetQuery(db, "SELECT * FROM top_news")
sources <- c("associated-press","al-jazeera-english","bbc-news","bloomberg",
"business-insider","breitbart-news","cnbc","cnn","google-news",
"independent","reuters","the-economist", "the-huffington-post",
"newsweek","the-new-york-times","the-wall-street-journal",
"the-washington-post","time","usa-today")
# ----------------
# Associated Press
# ----------------
scrape_news <- function(news_source, news_url){
page <- xml2::read_html(news_url)
if(news_source=="associated-press"){
# get particular content from page
content <- rvest::html_nodes(page, "p")
#convert to words
text <- rvest::html_text(content)
# remove photo and link captions from beginning
text <- text[substr(text, 0, 1) != "\n"]
# remove authors/credits from end
cutoff <- grep("___",  text)[1] - 1
if(!is.na(cutoff)){
text <- text[1:cutoff]}
# collapse vector into one string
text <- paste0(text, collapse = " | ")
# remove city from beginning of article
text <- gsub(".*(AP)) ", "", text)}
text
}
news$articles.url[news$source=="associated-press"]
scrape_news("associated-press", ap[1])
library(RSQLite)
library(tidyverse)
library(tm)
library("XML")
library("rvest")
db <- dbConnect(RSQLite::SQLite(), dbname="news_saturation (research).sqlite")
news <- dbGetQuery(db, "SELECT * FROM top_news")
sources <- c("associated-press","al-jazeera-english","bbc-news","bloomberg",
"business-insider","breitbart-news","cnbc","cnn","google-news",
"independent","reuters","the-economist", "the-huffington-post",
"newsweek","the-new-york-times","the-wall-street-journal",
"the-washington-post","time","usa-today")
# News scraping function
scrape_news <- function(news_source, news_url){
page <- xml2::read_html(news_url)
if(news_source=="associated-press"){
# get particular content from page
content <- rvest::html_nodes(page, "p")
#convert to words
text <- rvest::html_text(content)
# remove photo and link captions from beginning
text <- text[substr(text, 0, 1) != "\n"]
# remove authors/credits from end
cutoff <- grep("___",  text)[1] - 1
if(!is.na(cutoff)){
text <- text[1:cutoff]}
# collapse vector into one string
text <- paste0(text, collapse = " | ")
# remove city from beginning of article
text <- gsub(".*(AP)) ", "", text)}
text
}
# ----------------
# Associated Press
# ----------------
ap <- news$articles.url[news$source=="associated-press"]
scrape_news("associated-press", ap[1])
scrape_news("associated-press", ap[1]) %>% tail
# get all articles in vector
ap <- news$articles.url[news$source=="associated-press"]
url_col <- character()
text_col <- character()
for(x in ap){
url_col <- c(url_col, scrape_news("associated-press", x))
text_col <- c(text_col, "associated-press")
}
length(url_col)
url_col
text_col
length(ap)
ap <- news$articles.url[news$source=="associated-press"]
a1 <- Sys.time()
url_col <- character()
text_col <- character()
for(x in ap){
url_col <- c(url_col, scrape_news("associated-press", x))
text_col <- c(text_col, "associated-press")
}
a2 <- Sys.time()
a2-a1
head(text_col, 50)
a2-a1
url_col[1:5]
text_col <- url_col
text_col
ap_text <- data.frame("articles.url"=ap,
"text"=text_col)
glimpse(ap_text)
?size
ap_text$articles.url <- as.character(ap_text$articles.url)
ap_text <- data.frame("articles.url"=ap,
"text"=text_col)
ap_text %>% dbWriteTable(conn = db, name = "ap_text")
dbDisconnect(db)
list.files()
readLines("news_scraper.R")
readLines("news_scraper.R", start=5)
readLines("news_scraper.R", -6)
readLines("news_scraper.R", n = -6)
readLines
?readLines
readLines("news_scraper.R")[-(1:5)]
